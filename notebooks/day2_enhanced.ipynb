{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Enhanced ML Anomaly Detection with Realistic Data\n",
    "\n",
    "Better signals, same algorithm - focusing on data quality and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Enhanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load enhanced dataset with utilization and environment context\n",
    "df = pd.read_csv(\"../data/enhanced_cost_data.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Services: {df['service'].unique()}\")\n",
    "print(f\"Environments: {df['environment'].unique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Domain-Driven Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain-driven feature engineering\n",
    "df[\"cost_per_hour\"] = df[\"cost\"] / df[\"usage_hours\"]\n",
    "df[\"cpu_cost_ratio\"] = df[\"cost\"] / (df[\"cpu_utilization\"] + 1)\n",
    "\n",
    "# Remove rows with invalid data\n",
    "df = df[df[\"usage_hours\"] > 0]\n",
    "\n",
    "print(f\"Features created. Shape after cleaning: {df.shape}\")\n",
    "df[[\"date\", \"cost\", \"cpu_utilization\", \"cost_per_hour\", \"cpu_cost_ratio\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Isolation Forest with Better Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for ML model (high-signal, low-noise)\n",
    "features = [\n",
    "    \"cost\",\n",
    "    \"usage_hours\",\n",
    "    \"cpu_utilization\",\n",
    "    \"cost_per_hour\",\n",
    "    \"cpu_cost_ratio\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# Train Isolation Forest with tuned parameters\n",
    "model = IsolationForest(\n",
    "    n_estimators=150,\n",
    "    contamination=0.12,  # expect 12% anomalies\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Predict anomalies (-1 = anomaly, 1 = normal)\n",
    "df[\"anomaly_score\"] = model.fit_predict(X)\n",
    "df[\"is_anomaly\"] = df[\"anomaly_score\"] == -1\n",
    "\n",
    "print(f\"Anomalies detected: {df['is_anomaly'].sum()}\")\n",
    "print(f\"Anomaly rate: {df['is_anomaly'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Anomaly Explanation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_anomaly(row):\n",
    "    if row[\"cpu_utilization\"] < 20 and row[\"cost\"] > 100:\n",
    "        return \"High cost with low CPU utilization â€“ possible idle resources\"\n",
    "    if row[\"environment\"] == \"dev\" and row[\"usage_hours\"] > 20:\n",
    "        return \"Dev resources running full-day â€“ scheduling recommended\"\n",
    "    if row[\"cost_per_hour\"] > 10:\n",
    "        return \"Extremely high cost per hour â€“ check instance sizing\"\n",
    "    return \"Unusual cost pattern detected\"\n",
    "\n",
    "df[\"explanation\"] = df.apply(explain_anomaly, axis=1)\n",
    "\n",
    "# Show detected anomalies with explanations\n",
    "print(\"\\nDetected Anomalies:\")\n",
    "anomalies = df[df[\"is_anomaly\"]][[\"date\", \"service\", \"environment\", \"cost\", \"cpu_utilization\", \"explanation\"]]\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visual Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# Plot 1: Cost over time\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(df[\"date\"], df[\"cost\"], label=\"Daily Cost\", linewidth=2)\n",
    "plt.scatter(\n",
    "    df[df[\"is_anomaly\"]][\"date\"],\n",
    "    df[df[\"is_anomaly\"]][\"cost\"],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    label=\"ML Detected Anomaly\",\n",
    "    zorder=5\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Enhanced Isolation Forest - Cloud Cost Anomaly Detection\")\n",
    "plt.ylabel(\"Cost ($)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: CPU vs Cost scatter\n",
    "plt.subplot(2,1,2)\n",
    "normal = df[~df[\"is_anomaly\"]]\n",
    "anomaly = df[df[\"is_anomaly\"]]\n",
    "plt.scatter(normal[\"cpu_utilization\"], normal[\"cost\"], alpha=0.6, label=\"Normal\")\n",
    "plt.scatter(anomaly[\"cpu_utilization\"], anomaly[\"cost\"], color=\"red\", s=100, label=\"Anomaly\")\n",
    "plt.xlabel(\"CPU Utilization (%)\")\n",
    "plt.ylabel(\"Cost ($)\")\n",
    "plt.title(\"CPU Utilization vs Cost\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Business-Aligned Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ground truth: business logic for anomalies\n",
    "df[\"true_anomaly\"] = (\n",
    "    (df[\"cpu_utilization\"] < 20) & (df[\"cost\"] > 100)  # High cost + low CPU\n",
    "    | (df[\"environment\"] == \"dev\") & (df[\"usage_hours\"] > 20)  # Dev running full-day\n",
    "    | (df[\"cost\"] > 150)  # Extremely high cost\n",
    ")\n",
    "\n",
    "print(f\"True anomalies (business logic): {df['true_anomaly'].sum()}\")\n",
    "print(f\"ML detected anomalies: {df['is_anomaly'].sum()}\")\n",
    "\n",
    "# Show comparison\n",
    "comparison = df[[\"date\", \"service\", \"environment\", \"cost\", \"cpu_utilization\", \"true_anomaly\", \"is_anomaly\"]]\n",
    "comparison[comparison[\"true_anomaly\"] | comparison[\"is_anomaly\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Enhanced Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "precision = precision_score(df[\"true_anomaly\"], df[\"is_anomaly\"])\n",
    "recall = recall_score(df[\"true_anomaly\"], df[\"is_anomaly\"])\n",
    "f1 = f1_score(df[\"true_anomaly\"], df[\"is_anomaly\"])\n",
    "\n",
    "print(\"=== ENHANCED MODEL PERFORMANCE ===\")\n",
    "print(f\"Precision: {precision:.3f} (How many alerts were correct)\")\n",
    "print(f\"Recall: {recall:.3f} (How many true issues we caught)\")\n",
    "print(f\"F1-Score: {f1:.3f} (Overall balance)\")\n",
    "\n",
    "# Business impact analysis\n",
    "total_anomaly_cost = df[df[\"is_anomaly\"]][\"cost\"].sum()\n",
    "avg_anomaly_cost = df[df[\"is_anomaly\"]][\"cost\"].mean()\n",
    "avg_normal_cost = df[~df[\"is_anomaly\"]][\"cost\"].mean()\n",
    "estimated_monthly_savings = total_anomaly_cost * 0.3\n",
    "\n",
    "print(f\"\\n=== BUSINESS IMPACT ===\")\n",
    "print(f\"Total anomalous spending: ${total_anomaly_cost:.2f}\")\n",
    "print(f\"ðŸ’° ESTIMATED MONTHLY SAVINGS: ${estimated_monthly_savings:.2f}\")\n",
    "print(f\"ðŸ“Š Cost efficiency improvement: {avg_anomaly_cost/avg_normal_cost:.1f}x reduction potential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Day 1 baseline (simple threshold method)\n",
    "cost_mean = df[\"cost\"].mean()\n",
    "cost_std = df[\"cost\"].std()\n",
    "df[\"baseline_anomaly\"] = df[\"cost\"] > (cost_mean + 2 * cost_std)\n",
    "\n",
    "# Baseline metrics\n",
    "baseline_precision = precision_score(df[\"true_anomaly\"], df[\"baseline_anomaly\"])\n",
    "baseline_recall = recall_score(df[\"true_anomaly\"], df[\"baseline_anomaly\"])\n",
    "baseline_f1 = f1_score(df[\"true_anomaly\"], df[\"baseline_anomaly\"])\n",
    "\n",
    "print(\"=== METHOD COMPARISON ===\")\n",
    "print(f\"{'Metric':<12} {'Baseline':<12} {'Enhanced ML':<12} {'Improvement':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Precision':<12} {baseline_precision:<12.3f} {precision:<12.3f} {precision/baseline_precision if baseline_precision > 0 else 'N/A':<12}\")\n",
    "print(f\"{'Recall':<12} {baseline_recall:<12.3f} {recall:<12.3f} {recall/baseline_recall if baseline_recall > 0 else 'N/A':<12}\")\n",
    "print(f\"{'F1-Score':<12} {baseline_f1:<12.3f} {f1:<12.3f} {f1/baseline_f1 if baseline_f1 > 0 else 'N/A':<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Enhanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save enhanced model\n",
    "joblib.dump(model, \"../models/enhanced_isolation_forest.pkl\")\n",
    "\n",
    "# Save feature names and metadata\n",
    "model_metadata = {\n",
    "    \"features\": features,\n",
    "    \"contamination\": 0.12,\n",
    "    \"n_estimators\": 150,\n",
    "    \"performance\": {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"../models/model_metadata.json\", \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(\"âœ… Enhanced model saved for API deployment\")\n",
    "print(f\"Model: ../models/enhanced_isolation_forest.pkl\")\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Performance: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}